# practice_keras   
작성자: 김현준(010-4890-5240 / ggkids9211@gmail.com)   

이 레퍼지토리는 케라스 입문을 위해 생성되었습니다.   
이곳은 다음의 케라스 기능을 연습합니다.   
1. Keras Stochastic Gradient Descent, SGD 연습.   

* * *   
## 세부 기능 정리    
### 1. Stochastic Gradient Descent, SGD    
> 확률적 경사 하강법이라고도 합니다.     
> 이것은 추출된 데이터 한개에 대해서 그래디언트를 계산하고, 경사 하강 알고리즘을 적용하는 것입니다.   
> 특징으로는 전체 데이터를 사용하는 것이 아니라 랜덤하게 추출한 일부 데이터를 학습에 사용하기 때문에, 학습의 중간과정에서 결과의 진폭이 크고 불안정하며, 학습 속도가 매우 빠른 것입니다.   
> 또한 데이터 하나씩 처리하기 때문에 오차율이 매우 크며, GPU의 성능을 모두 사용하지 못하는 단점이 있습니다.    
> 이러한 단점을 보완하기 위해 나온 방법은 Mini Batch를 이용한 방법이며 SGD보다 노이즈를 줄이면서도 전체 배치를 더 효율적으로 학습하는 것으로 알려져 있습니다.   
> 이렇게 경사 하강법에도 몇가지 계산 방법이 있는데 크게는 이 세가지 입니다.   
> 1. Batch: 모든 데이터를 한꺼번에 학습하는 방법입니다. 부드럽게 학습되는 것이 특징이나 샘플 개수 만큼 계산해야하기 때문에 시간이 다소 걸립니다.   
> 2. Stochastic: 데이터를 랜덤으로 추출하여 학습해보고, 이를 모든 학습 데이터에 적용해보는 계산 방법입니다. 위에서도 언급했듯이 학습속도는 매우 빠르나 학습 중간과정의 진폭이 크고 불안정합니다.   
> 3. Mini Batch: 전체 학습 데이터를 배치 사이즈로 나눠서 순차적으로 학습합니다. 일반적인 딥러닝에 사용되는 방법이며 Batch 보다 학습이 빠르고 SGD 보다 낮은 오차율을 가지고 있습니다.   
예제 링크: [SGD 예제 코드](https://github.com/Tom-HJ/Tom-HJ-practice_keras/blob/main/0_SGD.py)